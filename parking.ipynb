{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "import requests\n",
    "import re\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "from twilio.rest import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Number of GPUs available: 1\n",
      "GPU 0 : NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "cuda_available = torch.cuda.is_available()\n",
    "print(\"CUDA available:\", cuda_available)\n",
    "if cuda_available:\n",
    "    print(\"Number of GPUs available:\", torch.cuda.device_count())\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(\"GPU\", i, \":\", torch.cuda.get_device_name(i))\n",
    "else:\n",
    "    print(\"No GPUs available, CPU will be used.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config_parking.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "input_path = config['rtsp_urls']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the credentials from the JSON file\n",
    "with open('credentials.json', 'r') as file:\n",
    "    credentials = json.load(file)\n",
    "\n",
    "API_TOKEN = credentials['API_TOKEN']\n",
    "PR_API_URL = credentials['PR_API_URL']\n",
    "\n",
    "# Twilio credentials and setup\n",
    "account_sid = credentials['account_sid']\n",
    "auth_token = credentials['auth_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(account_sid, auth_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov5mu.pt')\n",
    "class_names = [\n",
    "    \"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "    \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "    \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\",\n",
    "    \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\",\n",
    "    \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\",\n",
    "    \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\",\n",
    "    \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\",\n",
    "    \"chair\", \"couch\", \"potted plant\", \"bed\", \"dining table\", \"toilet\", \"TV\", \"laptop\",\n",
    "    \"mouse\", \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\",\n",
    "    \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\",\n",
    "    \"toothbrush\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(input_path):\n",
    "    is_image = input_path.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))\n",
    "    if is_image:\n",
    "        frame = cv2.imread(input_path)\n",
    "        if frame is None:\n",
    "            print(\"Error: Unable to load image\")\n",
    "            exit()\n",
    "    else:\n",
    "        cap = cv2.VideoCapture(input_path)\n",
    "else:\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Unable to open video stream\")\n",
    "        exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "parking_log = {}\n",
    "processed_cars = set() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_license_plate(plate_number):\n",
    "    plate_number = plate_number.upper()\n",
    "    match = re.match(r\"([A-Z]{2})(\\d{2})([A-Z]{2})(\\d{4})\", plate_number)\n",
    "    \n",
    "    if match:\n",
    "        formatted_plate = f\"{match.group(1)} {match.group(2)} {match.group(3)} {match.group(4)}\"\n",
    "        return formatted_plate\n",
    "    else:\n",
    "        return plate_number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twilio notification function\n",
    "def send_notification(plate, park_time, entry=True):\n",
    "    message_body = f\"Vehicle with Registration No.: {plate} has {'entered' if entry else 'exited'} SP CAR PARKING At {park_time}. Thank You\"\n",
    "    message = client.messages.create(\n",
    "        body=message_body,\n",
    "        from_='whatsapp:+14155238886',  # Twilio number\n",
    "        to='whatsapp:+919842138883'  # Your phone number to receive notifications\n",
    "    )\n",
    "    print(f\"Notification sent: {message_body}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to log car entry and send notification\n",
    "def log_car_entry(plate):\n",
    "    entry_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    parking_log[plate] = {'entry': entry_time}\n",
    "    print(f\"Car {plate} entered at {entry_time}\")\n",
    "    send_notification(plate, entry_time, entry=True)  # Send entry notification\n",
    "\n",
    "# Function to log car exit and send notification\n",
    "def log_car_exit(plate):\n",
    "    exit_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    if plate in parking_log:\n",
    "        parking_log[plate]['exit'] = exit_time\n",
    "        print(f\"Car {plate} exited at {exit_time}\")\n",
    "        send_notification(plate, exit_time, entry=False)  # Send exit notification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to recognize license plate using Plate Recognizer API\n",
    "def recognize_plate(car_image):\n",
    "    success, image_jpg = cv2.imencode('.jpg', car_image)\n",
    "    files = {'upload': image_jpg.tobytes()}\n",
    "    headers = {'Authorization': f'Token {API_TOKEN}'}\n",
    "\n",
    "    # Send the image to Plate Recognizer\n",
    "    response = requests.post(PR_API_URL, headers=headers, files=files)\n",
    "\n",
    "    if response.status_code == 201:  # 201 indicates successful processing\n",
    "        data = response.json()\n",
    "        if len(data['results']) > 0:\n",
    "            # Extract the main license plate\n",
    "            plate_number = data['results'][0]['plate']\n",
    "            \n",
    "            # Format the plate number\n",
    "            formatted_plate = format_license_plate(plate_number)\n",
    "            \n",
    "            \n",
    "            \n",
    "            # Print the detected plate and timestamp\n",
    "            print(f\"License Plate Detected: {formatted_plate}\")\n",
    "            \n",
    "            \n",
    "            # Check if it's a new car (entry) or existing car (exit)\n",
    "            if formatted_plate not in parking_log:\n",
    "                log_car_entry(formatted_plate)\n",
    "            else:\n",
    "                log_car_exit(formatted_plate)\n",
    "            \n",
    "            return formatted_plate\n",
    "        else:\n",
    "            print(\"No plate detected.\")\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}, {response.text}\")\n",
    "    return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD_LINE_Y = 580  \n",
    "# Function to check if the car has crossed the threshold line\n",
    "def has_crossed_threshold(y2):\n",
    "    return y2 > THRESHOLD_LINE_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    return image  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize the video frame while maintaining aspect ratio\n",
    "def resize_frame(frame, width, height):\n",
    "    h, w, _ = frame.shape\n",
    "    aspect_ratio = w / h\n",
    "    if w > h:\n",
    "        new_width = width\n",
    "        new_height = int(new_width / aspect_ratio)\n",
    "    else:\n",
    "        new_height = height\n",
    "        new_width = int(new_height * aspect_ratio)\n",
    "    return cv2.resize(frame, (new_width, new_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    results = model(image)\n",
    "    for result in results:\n",
    "        boxes = result.boxes.xyxy  \n",
    "        classes = result.boxes.cls  \n",
    "\n",
    "        for i, box in enumerate(boxes):\n",
    "            class_id = int(classes[i])\n",
    "            if class_names[class_id] == \"car\":  \n",
    "                x1, y1, x2, y2 = map(int, box)  \n",
    "                car_region = image[y1:y2, x1:x2]  \n",
    "                car_region = preprocess_image(car_region)\n",
    "                recognize_plate(car_region)\n",
    "    \n",
    "    annotated_frame = results[0].plot()  # Visualize the results\n",
    "    cv2.imshow('YOLOv8 Inference', annotated_frame)\n",
    "    cv2.waitKey(0)  # Wait for key press to close the image window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def capture_and_detect():\n",
    "#     while True:\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             print(\"Failed to retrieve frame from camera or video\")\n",
    "#             break\n",
    "        \n",
    "#         # Resize the frame to fit the full-screen window\n",
    "#         frame_resized = resize_frame(frame, 1080, 720)\n",
    "        \n",
    "#         # Run YOLO detection\n",
    "#         results = model(frame_resized)\n",
    "\n",
    "#         if results and len(results) > 0:\n",
    "#             # If YOLO detects objects, annotate the frame\n",
    "#             annotated_frame = results[0].plot()\n",
    "#         else:\n",
    "#             # If no detections, use the resized frame as the annotated frame\n",
    "#             annotated_frame = frame_resized.copy()\n",
    "        \n",
    "#         # Check for car detections and process them\n",
    "#         for result in results:\n",
    "#             boxes = result.boxes.xyxy  # Get the bounding boxes\n",
    "#             classes = result.boxes.cls  # Get the class labels\n",
    "\n",
    "#             for i, box in enumerate(boxes):\n",
    "#                 class_id = int(classes[i])\n",
    "#                 if class_names[class_id] == \"car\":  # Only process cars\n",
    "#                     x1, y1, x2, y2 = map(int, box)  # Extract bounding box\n",
    "                    \n",
    "#                     # Check if the car has crossed the Y-threshold line\n",
    "#                     if has_crossed_threshold(y2):\n",
    "#                         car_id = (x1, y1, x2, y2)\n",
    "\n",
    "#                         # If this car has not been processed yet, process it\n",
    "#                         if car_id not in processed_cars:\n",
    "#                             car_region = frame_resized[y1:y2, x1:x2]  # Crop the car region\n",
    "#                             # recognize_plate(car_region)  # Send the cropped image for recognition\n",
    "#                             processed_cars.add(car_id)\n",
    "                        \n",
    "#         # Draw the threshold line on the annotated frame\n",
    "#         cv2.line(annotated_frame, (0, THRESHOLD_LINE_Y), (annotated_frame.shape[1], THRESHOLD_LINE_Y), (0, 255, 0), 2)  # Green line\n",
    "\n",
    "#         # Visualize the result\n",
    "#         cv2.imshow('YOLOv8 Inference', annotated_frame)\n",
    "\n",
    "#         # Press 'q' to exit the loop\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#             break\n",
    "\n",
    "#     cap.release()\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "# # Initialize video capture\n",
    "# cap = cv2.VideoCapture(input_path)\n",
    "# if not cap.isOpened():\n",
    "#     print(\"Error: Unable to open video stream\")\n",
    "#     exit()\n",
    "\n",
    "# # Set the window to full screen or specific size\n",
    "# #cv2.namedWindow('YOLOv8 Inference', cv2.WINDOW_NORMAL)\n",
    "# #cv2.setWindowProperty('YOLOv8 Inference', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)  # For full-screen display\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute image sharpness using Laplacian variance\n",
    "def calculate_sharpness(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "    laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()  # Calculate the variance of the Laplacian\n",
    "    return laplacian_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def capture_and_detect():\n",
    "#     while True:\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             print(\"Failed to retrieve frame from camera or video\")\n",
    "#             break\n",
    "        \n",
    "#         # Resize the frame to fit the full-screen window\n",
    "#         frame_resized = resize_frame(frame, 1080, 720)\n",
    "        \n",
    "#         # Run YOLO detection\n",
    "#         results = model(frame_resized)\n",
    "\n",
    "#         if results and len(results) > 0:\n",
    "#             # If YOLO detects objects, annotate the frame\n",
    "#             annotated_frame = results[0].plot()\n",
    "#         else:\n",
    "#             # If no detections, use the resized frame as the annotated frame\n",
    "#             annotated_frame = frame_resized.copy()\n",
    "        \n",
    "#         # Check for car detections and process them\n",
    "#         for result in results:\n",
    "#             boxes = result.boxes.xyxy  # Get the bounding boxes\n",
    "#             classes = result.boxes.cls  # Get the class labels\n",
    "\n",
    "#             for i, box in enumerate(boxes):\n",
    "#                 class_id = int(classes[i])\n",
    "#                 if class_names[class_id] == \"car\":  # Only process cars\n",
    "#                     x1, y1, x2, y2 = map(int, box)  # Extract bounding box\n",
    "                    \n",
    "#                     # Check if the car has crossed the Y-threshold line\n",
    "#                     if has_crossed_threshold(y2):\n",
    "#                         car_id = (x1, y1, x2, y2)\n",
    "\n",
    "#                         # If this car has not been processed yet, process it\n",
    "#                         if car_id not in processed_cars:\n",
    "#                             car_region = frame_resized[y1:y2, x1:x2]  # Crop the car region\n",
    "\n",
    "#                             # Display the cropped car image in a new window for testing\n",
    "#                             cv2.imshow(\"Cropped Car\", car_region)\n",
    "#                             print(\"Car has crossed the threshold. Showing cropped car image.\")\n",
    "                            \n",
    "#                             # Wait for a key press to close the cropped car window\n",
    "#                             cv2.waitKey(0)\n",
    "#                             cv2.destroyWindow(\"Cropped Car\")  # Close the cropped car window after key press\n",
    "\n",
    "#                             # Add the car to the processed set\n",
    "#                             processed_cars.add(car_id)\n",
    "                        \n",
    "#         # Draw the threshold line on the annotated frame\n",
    "#         cv2.line(annotated_frame, (0, THRESHOLD_LINE_Y), (annotated_frame.shape[1], THRESHOLD_LINE_Y), (0, 255, 0), 2)  # Green line\n",
    "\n",
    "#         # Visualize the result\n",
    "#         cv2.imshow('YOLOv8 Inference', annotated_frame)\n",
    "\n",
    "#         # Press 'q' to exit the loop\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#             break\n",
    "\n",
    "#     cap.release()\n",
    "#     cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def capture_and_detect():\n",
    "    car_detected = False  # Flag to indicate when the car has touched the threshold\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to retrieve frame from camera or video\")\n",
    "            break\n",
    "        \n",
    "        # Resize the frame to fit the full-screen window\n",
    "        frame_resized = resize_frame(frame, 1080, 720)\n",
    "        \n",
    "        # Run YOLO detection\n",
    "        results = model(frame_resized)\n",
    "\n",
    "        if results and len(results) > 0:\n",
    "            # If YOLO detects objects, annotate the frame\n",
    "            annotated_frame = results[0].plot()\n",
    "        else:\n",
    "            # If no detections, use the resized frame as the annotated frame\n",
    "            annotated_frame = frame_resized.copy()\n",
    "        \n",
    "        # Check for car detections and process them\n",
    "        for result in results:\n",
    "            boxes = result.boxes.xyxy  # Get the bounding boxes\n",
    "            classes = result.boxes.cls  # Get the class labels\n",
    "\n",
    "            for i, box in enumerate(boxes):\n",
    "                class_id = int(classes[i])\n",
    "                if class_names[class_id] == \"car\":  # Only process cars\n",
    "                    x1, y1, x2, y2 = map(int, box)  # Extract bounding box\n",
    "                    \n",
    "                    # Check if the car has crossed the Y-threshold line\n",
    "                    if has_crossed_threshold(y2) and not car_detected:\n",
    "                        car_detected = True  # Mark the car as detected\n",
    "                        print(\"Car has touched the threshold. Capturing snapshot.\")\n",
    "\n",
    "                        # Crop the car region immediately after crossing the threshold\n",
    "                        car_region = frame_resized[y1:y2, x1:x2]\n",
    "\n",
    "                        # Display the cropped car image\n",
    "                        cv2.imshow(\"Cropped Car Image\", car_region)\n",
    "                        recognize_plate(car_region)\n",
    "\n",
    "                        # Wait for a key press to close the window and stop further processing\n",
    "                        key = cv2.waitKey(0)\n",
    "                        \n",
    "                        # Check if the window was successfully opened before destroying it\n",
    "                        if cv2.getWindowProperty(\"Cropped Car Image\", cv2.WND_PROP_VISIBLE) >= 1:\n",
    "                            cv2.destroyWindow(\"Cropped Car Image\")\n",
    "\n",
    "                        return  # Exit after capturing and processing the first car\n",
    "\n",
    "        # Draw the threshold line on the annotated frame\n",
    "        cv2.line(annotated_frame, (0, THRESHOLD_LINE_Y), (annotated_frame.shape[1], THRESHOLD_LINE_Y), (0, 255, 0), 2)  # Green line\n",
    "\n",
    "        # Visualize the result\n",
    "        cv2.imshow('YOLOv8 Inference', annotated_frame)\n",
    "\n",
    "        # Press 'q' to exit the loop\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 car, 31.2ms\n",
      "Speed: 2.0ms preprocess, 31.2ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "License Plate Detected: MH 20 EE 7602\n",
      "Car MH 20 EE 7602 entered at 2024-09-27 11:45:44\n",
      "Notification sent: Vehicle with Registration No.: MH 20 EE 7602 has entered SP CAR PARKING At 2024-09-27 11:45:44. Thank You\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(input_path) and is_image:\n",
    "    process_image(frame) \n",
    "else:\n",
    "    capture_and_detect()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
